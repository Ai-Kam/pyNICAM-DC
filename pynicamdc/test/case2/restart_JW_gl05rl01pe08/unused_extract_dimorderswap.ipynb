{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "851916f2-9028-4573-993d-83cb3e4707dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'restart_all_GL05RL01z40.pe000008'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Mapping from datatype code to NumPy dtype\u001b[39;00m\n\u001b[32m     10\u001b[39m dtype_map = {\u001b[32m0\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mf4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mf8\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mi4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m3\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mi8\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Read metadata (header + note)\u001b[39;00m\n\u001b[32m     14\u001b[39m     header = f.read(\u001b[32m64\u001b[39m).decode(errors=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m).strip()\n\u001b[32m     15\u001b[39m     note = f.read(\u001b[32m256\u001b[39m).decode(errors=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/jax_mpi/lib/python3.11/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'restart_all_GL05RL01z40.pe000008'"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# File path (update if needed)\n",
    "file_path = \"restart_all_GL05RL01z40.pe000000\"\n",
    "output_json = file_path+\"_reversed.json\"\n",
    "\n",
    "# Mapping from datatype code to NumPy dtype\n",
    "dtype_map = {0: \"f4\", 1: \"f8\", 2: \"i4\", 3: \"i8\"}\n",
    "\n",
    "with open(file_path, \"rb\") as f:\n",
    "    # Read metadata (header + note)\n",
    "    header = f.read(64).decode(errors=\"ignore\").strip()\n",
    "    note = f.read(256).decode(errors=\"ignore\").strip()\n",
    "\n",
    "    # Read global file metadata\n",
    "    fmode, endiantype, grid_topology, glevel, rlevel, num_of_rgn = struct.unpack(\">6I\", f.read(4 * 6))\n",
    "    \n",
    "    # Read region IDs\n",
    "    rgnid = struct.unpack(f\">{num_of_rgn}I\", f.read(4 * num_of_rgn))\n",
    "    \n",
    "    # Read number of data variables\n",
    "    num_of_data = struct.unpack(\">I\", f.read(4))[0]\n",
    "\n",
    "    # Dictionary to store extracted data\n",
    "    dataset = {\n",
    "        \"Header\": header,\n",
    "        \"Note\": note,\n",
    "        \"File Mode\": fmode,\n",
    "        \"Endian Type\": endiantype,\n",
    "        \"Grid Topology\": grid_topology,\n",
    "        \"Grid Level\": glevel,\n",
    "        \"Resolution Level\": rlevel,\n",
    "        \"Number of Regions\": num_of_rgn,\n",
    "        \"Region IDs\": list(rgnid),\n",
    "        \"Number of Data Entries\": num_of_data,\n",
    "        \"Variables\": {}\n",
    "    }\n",
    "\n",
    "    # Expected shape before reordering: (Region, Layer, ij)\n",
    "    expected_shape = (5, 42, 324)\n",
    "\n",
    "    # Process each data entry\n",
    "    for _ in range(num_of_data):\n",
    "        # Read variable metadata\n",
    "        varname = f.read(16).decode(errors=\"ignore\").strip()\n",
    "        description = f.read(64).decode(errors=\"ignore\").strip()\n",
    "        unit = f.read(16).decode(errors=\"ignore\").strip()\n",
    "        layername = f.read(16).decode(errors=\"ignore\").strip()\n",
    "        note = f.read(256).decode(errors=\"ignore\").strip()\n",
    "\n",
    "        # Read integer fields\n",
    "        datasize, datatype, _, _ = struct.unpack(\">Q3I\", f.read(8 + 4 * 3))\n",
    "\n",
    "        # Read time information\n",
    "        time_start, time_end = struct.unpack(\">QQ\", f.read(8 * 2))\n",
    "\n",
    "        # Read raw data\n",
    "        raw_data = f.read(datasize)\n",
    "\n",
    "        # Convert to NumPy array in correct format (big-endian float)\n",
    "        data_array = np.frombuffer(raw_data, dtype=np.dtype(f\">{dtype_map[datatype]}\"))\n",
    "\n",
    "        # Ensure the correct number of elements before reshaping\n",
    "        if data_array.size != np.prod(expected_shape):\n",
    "            print(f\"Warning: Variable {varname} has unexpected size {data_array.size}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Reshape into (Region, Layer, ij)\n",
    "        data_array = data_array.reshape(expected_shape)\n",
    "\n",
    "        # Reverse dimensions to (ij, Layer, Region)\n",
    "        data_array = np.transpose(data_array, (2, 1, 0))\n",
    "\n",
    "        # Store variable data\n",
    "        dataset[\"Variables\"][varname] = {\n",
    "            \"Description\": description,\n",
    "            \"Unit\": unit,\n",
    "            \"Layer Name\": layername,\n",
    "            \"Time Start\": time_start,\n",
    "            \"Time End\": time_end,\n",
    "            \"Data\": data_array.tolist()  # Convert NumPy array to list for JSON serialization\n",
    "        }\n",
    "\n",
    "# Save as JSON file\n",
    "with open(output_json, \"w\") as json_file:\n",
    "    json.dump(dataset, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON file saved as {output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4fe08-7f60-4e4d-98a2-6175102f8dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jax_mpi)",
   "language": "python",
   "name": "jax_mpi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
